{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436bcef1",
   "metadata": {},
   "source": [
    "# üîß PaniniFS Debug - Local VS Code Testing\n",
    "\n",
    "Version locale pour debugger le notebook Colab dans VS Code\n",
    "- Mock environment Google Colab\n",
    "- Debug direct des erreurs\n",
    "- Test ecosystem GitHub autonomous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72597e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß SETUP DEBUG ENVIRONMENT\n",
    "import sys\n",
    "sys.path.append('/home/stephane/GitHub/PaniniFS-1/Copilotage/scripts')\n",
    "\n",
    "from colab_debug_environment import setup_colab_debug_environment\n",
    "workspace = setup_colab_debug_environment()\n",
    "\n",
    "print(\"üîß Debug environment ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4204921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üå•Ô∏è TEST AUTONOMOUS ECOSYSTEM ACCESS\n",
    "# Copie du code de la premi√®re cellule pour debug\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import psutil\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# V√©rification GPU (CPU en local)\n",
    "print(\"üîç DIAGNOSTIC LOCAL\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üì± Device: {device}\")\n",
    "print(f\"üíª RAM: {psutil.virtual_memory().total / 1e9:.1f} GB\")\n",
    "print(f\"üîß CPU cores: {psutil.cpu_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU non disponible - mode CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TEST RAPIDE - ACC√àS DONN√âES LOCALES\n",
    "# Version rapide sans clonage pour debug imm√©diat\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "def quick_local_data_test():\n",
    "    \"\"\"Test rapide des donn√©es locales disponibles\"\"\"\n",
    "    \n",
    "    print(\"üß™ DEBUG RAPIDE: Donn√©es locales\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Sources locales √† tester (sans clonage)\n",
    "    local_sources = [\n",
    "        '/home/stephane/GitHub/PaniniFS-1',\n",
    "        '/home/stephane/GitHub/Pensine', \n",
    "        '/home/stephane/GitHub'\n",
    "    ]\n",
    "    \n",
    "    data_sources = []\n",
    "    \n",
    "    for source_path in local_sources:\n",
    "        path = Path(source_path)\n",
    "        print(f\"\\n\udcc1 Test: {source_path}\")\n",
    "        \n",
    "        if path.exists():\n",
    "            # Compter fichiers rapidement (limite pour √©viter la lenteur)\n",
    "            py_files = list(path.rglob(\"*.py\"))[:100]  # Max 100 pour vitesse\n",
    "            md_files = list(path.rglob(\"*.md\"))[:50]   # Max 50 pour vitesse\n",
    "            \n",
    "            total_files = len(py_files) + len(md_files)\n",
    "            \n",
    "            print(f\"   ‚úÖ Trouv√©: {len(py_files)} Python, {len(md_files)} Markdown\")\n",
    "            \n",
    "            if total_files > 0:\n",
    "                data_sources.append({\n",
    "                    'path': str(path),\n",
    "                    'py_files': len(py_files),\n",
    "                    'md_files': len(md_files),\n",
    "                    'total_files': total_files,\n",
    "                    'type': 'local'\n",
    "                })\n",
    "        else:\n",
    "            print(f\"   ‚ùå Non trouv√©: {source_path}\")\n",
    "    \n",
    "    print(f\"\\nüìä R√âSUM√â RAPIDE:\")\n",
    "    print(f\"   \udcc1 Sources trouv√©es: {len(data_sources)}\")\n",
    "    \n",
    "    for source in data_sources:\n",
    "        print(f\"   {source['path']}: {source['total_files']} fichiers\")\n",
    "    \n",
    "    return data_sources\n",
    "\n",
    "# Ex√©cuter test rapide\n",
    "start_time = time.time()\n",
    "local_sources = quick_local_data_test()\n",
    "test_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Test termin√© en {test_time:.2f}s\")\n",
    "print(f\"üéØ Sources disponibles: {len(local_sources)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ude80 TEST RAPIDE EXTRACTION CONTENU\n",
    "# Version optimis√©e pour √©viter la lenteur\n",
    "\n",
    "def quick_content_extraction_test(sources, max_files=50):\n",
    "    \"\"\"Test rapide d'extraction de contenu (limit√© √† 50 fichiers)\"\"\"\n",
    "    \n",
    "    print(\"\ude80 DEBUG: Extraction contenu rapide\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    documents = []\n",
    "    file_metadata = []\n",
    "    \n",
    "    extensions = {'.py': 'Python', '.md': 'Markdown', '.txt': 'Text'}\n",
    "    \n",
    "    files_processed = 0\n",
    "    \n",
    "    for source in sources[:2]:  # Limiter √† 2 sources max\n",
    "        source_path = Path(source['path'])\n",
    "        print(f\"\\nüìÅ Processing: {source_path.name}\")\n",
    "        \n",
    "        for ext, file_type in extensions.items():\n",
    "            for file_path in source_path.rglob(f\"*{ext}\"):\n",
    "                if files_processed >= max_files:\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    # Ignorer fichiers volumineux\n",
    "                    if file_path.stat().st_size > 100 * 1024:  # 100KB max\n",
    "                        continue\n",
    "                    \n",
    "                    # Lire contenu (premiers 500 chars seulement)\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        content = f.read(500)  # Limite pour vitesse\n",
    "                    \n",
    "                    if len(content.strip()) < 50:\n",
    "                        continue\n",
    "                    \n",
    "                    # Document simplifi√©\n",
    "                    doc_text = f\"{file_type}/{file_path.name}: {content}\"\n",
    "                    documents.append(doc_text)\n",
    "                    \n",
    "                    file_metadata.append({\n",
    "                        'path': str(file_path),\n",
    "                        'type': file_type,\n",
    "                        'size': len(content)\n",
    "                    })\n",
    "                    \n",
    "                    files_processed += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ö†Ô∏è Erreur {file_path.name}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if files_processed >= max_files:\n",
    "                break\n",
    "        \n",
    "        if files_processed >= max_files:\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nüìä EXTRACTION RAPIDE:\")\n",
    "    print(f\"   üìÑ Documents extraits: {len(documents)}\")\n",
    "    print(f\"   üìÅ Fichiers analys√©s: {len(file_metadata)}\")\n",
    "    \n",
    "    # Exemple de contenu\n",
    "    if documents:\n",
    "        print(f\"\\nüìù Exemple document:\")\n",
    "        print(f\"   {documents[0][:100]}...\")\n",
    "    \n",
    "    return documents, file_metadata\n",
    "\n",
    "# Test uniquement si on a des sources\n",
    "if 'local_sources' in locals() and local_sources:\n",
    "    start_time = time.time()\n",
    "    test_docs, test_metadata = quick_content_extraction_test(local_sources)\n",
    "    extraction_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è Extraction termin√©e en {extraction_time:.2f}s\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas de sources locales trouv√©es, skip extraction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc38f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° TEST RAPIDE EMBEDDINGS\n",
    "# Version optimis√©e CPU/GPU avec fallback\n",
    "\n",
    "def quick_embeddings_test(documents=None, max_docs=20):\n",
    "    \"\"\"Test rapide des embeddings (20 docs max pour vitesse)\"\"\"\n",
    "    \n",
    "    print(\"‚ö° DEBUG: Test embeddings rapide\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Cr√©er donn√©es de test si pas de documents\n",
    "    if not documents:\n",
    "        documents = [\n",
    "            \"Python programming language test document\",\n",
    "            \"Rust systems programming memory safety\",\n",
    "            \"JavaScript web development framework\",\n",
    "            \"Machine learning artificial intelligence\",\n",
    "            \"Database systems distributed computing\"\n",
    "        ] * 4  # 20 documents de test\n",
    "    \n",
    "    # Limiter pour vitesse\n",
    "    test_docs = documents[:max_docs]\n",
    "    print(f\"\udcca Test avec {len(test_docs)} documents\")\n",
    "    \n",
    "    try:\n",
    "        print(\"üì¶ Installation sentence-transformers si n√©cessaire...\")\n",
    "        \n",
    "        # Test import\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            print(\"‚úÖ sentence-transformers disponible\")\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è Installation sentence-transformers...\")\n",
    "            import subprocess\n",
    "            subprocess.run([sys.executable, '-m', 'pip', 'install', 'sentence-transformers'], \n",
    "                         capture_output=True, timeout=60)\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            print(\"‚úÖ sentence-transformers install√©\")\n",
    "        \n",
    "        # Mod√®le l√©ger pour test rapide\n",
    "        print(\"üîÑ Chargement mod√®le l√©ger...\")\n",
    "        model_name = 'all-MiniLM-L6-v2'  # Mod√®le rapide\n",
    "        \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model = SentenceTransformer(model_name, device=device)\n",
    "        print(f\"‚úÖ Mod√®le charg√© sur {device}\")\n",
    "        \n",
    "        # Embeddings rapides\n",
    "        start_time = time.time()\n",
    "        embeddings = model.encode(test_docs, batch_size=16, show_progress_bar=True)\n",
    "        embedding_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nüìä R√âSULTATS EMBEDDINGS:\")\n",
    "        print(f\"   üìÑ Documents: {len(test_docs)}\")\n",
    "        print(f\"   üìä Forme embeddings: {embeddings.shape}\")\n",
    "        print(f\"   ‚è±Ô∏è Temps: {embedding_time:.2f}s\")\n",
    "        print(f\"   ‚ö° Throughput: {len(test_docs)/embedding_time:.0f} docs/sec\")\n",
    "        print(f\"   üéØ Device: {device}\")\n",
    "        \n",
    "        return embeddings, embedding_time\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERREUR EMBEDDINGS:\")\n",
    "        print(f\"   Type: {type(e).__name__}\")\n",
    "        print(f\"   Message: {str(e)}\")\n",
    "        \n",
    "        # Stack trace pour debug\n",
    "        import traceback\n",
    "        print(f\"\\nüìã Stack trace:\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return None, 0\n",
    "\n",
    "# Test embeddings\n",
    "if 'test_docs' in locals() and test_docs:\n",
    "    print(\"üß™ Test avec documents extraits\")\n",
    "    embeddings_result, emb_time = quick_embeddings_test(test_docs)\n",
    "else:\n",
    "    print(\"üß™ Test avec documents synth√©tiques\")\n",
    "    embeddings_result, emb_time = quick_embeddings_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9563e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä RAPPORT DEBUG FINAL\n",
    "# Synth√®se rapide des tests\n",
    "\n",
    "def generate_debug_report():\n",
    "    \"\"\"G√©n√©rer rapport de debug rapide\"\"\"\n",
    "    \n",
    "    print(\"üìä RAPPORT DEBUG FINAL\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Collecter r√©sultats des tests\n",
    "    report = {\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'device': device if 'device' in locals() else 'unknown',\n",
    "        'sources_found': len(local_sources) if 'local_sources' in locals() else 0,\n",
    "        'documents_extracted': len(test_docs) if 'test_docs' in locals() else 0,\n",
    "        'embeddings_success': embeddings_result is not None if 'embeddings_result' in locals() else False,\n",
    "        'total_time': 0\n",
    "    }\n",
    "    \n",
    "    print(f\"üïê Timestamp: {report['timestamp']}\")\n",
    "    print(f\"üíª Device: {report['device']}\")\n",
    "    print(f\"üìÅ Sources trouv√©es: {report['sources_found']}\")\n",
    "    print(f\"üìÑ Documents extraits: {report['documents_extracted']}\")\n",
    "    print(f\"‚ö° Embeddings: {'‚úÖ Succ√®s' if report['embeddings_success'] else '‚ùå √âchec'}\")\n",
    "    \n",
    "    # Diagnostics\n",
    "    print(f\"\\nüîß DIAGNOSTICS:\")\n",
    "    \n",
    "    if report['sources_found'] == 0:\n",
    "        print(\"   ‚ö†Ô∏è Aucune source de donn√©es trouv√©e\")\n",
    "        print(\"   üí° V√©rifiez les chemins d'acc√®s aux repos\")\n",
    "    \n",
    "    if report['documents_extracted'] == 0:\n",
    "        print(\"   ‚ö†Ô∏è Aucun document extrait\")\n",
    "        print(\"   üí° V√©rifiez les permissions de fichiers\")\n",
    "    \n",
    "    if not report['embeddings_success']:\n",
    "        print(\"   ‚ùå Probl√®me avec les embeddings\")\n",
    "        print(\"   üí° Installez: pip install sentence-transformers\")\n",
    "    \n",
    "    # Recommandations\n",
    "    print(f\"\\nüí° RECOMMANDATIONS:\")\n",
    "    \n",
    "    if report['embeddings_success'] and report['documents_extracted'] > 0:\n",
    "        print(\"   ‚úÖ Tests locaux r√©ussis!\")\n",
    "        print(\"   üöÄ Le notebook Colab devrait fonctionner\")\n",
    "        print(\"   üîß Probl√®me probablement dans l'environnement Colab\")\n",
    "    else:\n",
    "        print(\"   üîß Probl√®mes d√©tect√©s en local\")\n",
    "        print(\"   üìã Corrigez d'abord les erreurs locales\")\n",
    "    \n",
    "    # Prochaines √©tapes\n",
    "    print(f\"\\nüéØ PROCHAINES √âTAPES:\")\n",
    "    print(\"   1. Si tests locaux OK: V√©rifier environnement Colab\")\n",
    "    print(\"   2. Si erreurs locales: Installer d√©pendances manquantes\")\n",
    "    print(\"   3. Optimiser pour √©viter timeouts\")\n",
    "    print(\"   4. Ajouter plus de gestion d'erreurs\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# G√©n√©rer rapport\n",
    "final_report = generate_debug_report()\n",
    "\n",
    "print(f\"\\nüéâ DEBUG TERMIN√â!\")\n",
    "print(f\"‚è±Ô∏è Tests rapides effectu√©s pour identifier l'erreur\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
