{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 semantic_processing_accelerated\\n",
        "**Auto-g\u00e9n\u00e9r\u00e9 depuis:** `/home/stephane/GitHub/PaniniFS-1/Copilotage/scripts/semantic_processing_example.py`\\n",
        "**GPU Acceleration:** Activ\u00e9\\n",
        "**Objectif:** Acc\u00e9l\u00e9ration 22-60x processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# \ud83d\udd27 SETUP ENVIRONNEMENT COLAB\\n",
        "import sys\\n",
        "print(f'\ud83d\udc0d Python: {sys.version}')\\n",
        "\\n",
        "# V\u00e9rifier GPU\\n",
        "try:\\n",
        "    import torch\\n",
        "    print(f'\ud83d\ude80 GPU disponible: {torch.cuda.is_available()}')\\n",
        "    if torch.cuda.is_available():\\n",
        "        print(f'   Device: {torch.cuda.get_device_name(0)}')\\n",
        "except:\\n",
        "    print('\u26a0\ufe0f PyTorch non disponible, installation...')\\n",
        "    !pip install torch\\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# \ud83d\udce6 INSTALLATION D\u00c9PENDANCES PaniniFS\\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn\\n",
        "!pip install sentence-transformers faiss-cpu\\n",
        "!pip install networkx community python-louvain\\n",
        "\\n",
        "# Clone repo si n\u00e9cessaire\\n",
        "import os\\n",
        "if not os.path.exists('PaniniFS-1'):\\n",
        "    !git clone https://github.com/stephanedenis/PaniniFS.git PaniniFS-1\\n",
        "    \\n",
        "# Changer working directory\\n",
        "os.chdir('PaniniFS-1')\\n",
        "print(f'\ud83d\udcc1 Working dir: {os.getcwd()}')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# \ud83d\ude80 SEMANTIC PROCESSING ACCELERATED",
        "# Exemple pour validation 22-60x speedup",
        "",
        "import time",
        "import numpy as np",
        "from sklearn.feature_extraction.text import TfidfVectorizer",
        "from sklearn.cluster import KMeans",
        "from sklearn.decomposition import PCA",
        "import matplotlib.pyplot as plt",
        "",
        "def generate_sample_data(n_docs=10000):",
        "    \"\"\"G\u00e9n\u00e9rer donn\u00e9es exemple pour test performance\"\"\"",
        "    print(f\"\ud83d\udcca G\u00e9n\u00e9ration {n_docs} documents de test...\")",
        "    ",
        "    # Simuler documents texte",
        "    topics = [",
        "        \"machine learning artificial intelligence neural networks\",",
        "        \"database storage systems distributed computing\",",
        "        \"web development frontend backend javascript python\",",
        "        \"mobile applications android ios swift kotlin\",",
        "        \"data science analytics visualization pandas numpy\"",
        "    ]",
        "    ",
        "    documents = []",
        "    for i in range(n_docs):",
        "        base_topic = topics[i % len(topics)]",
        "        # Ajouter variations",
        "        doc = f\"{base_topic} research development {i} analysis implementation\"",
        "        documents.append(doc)",
        "    ",
        "    return documents",
        "",
        "def accelerated_clustering(documents, n_clusters=5):",
        "    \"\"\"Clustering acc\u00e9l\u00e9r\u00e9 avec GPU si disponible\"\"\"",
        "    print(f\"\u26a1 CLUSTERING ACC\u00c9L\u00c9R\u00c9...\")",
        "    start_time = time.time()",
        "    ",
        "    # Vectorisation TF-IDF",
        "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')",
        "    X = vectorizer.fit_transform(documents)",
        "    ",
        "    # Clustering K-means",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)",
        "    clusters = kmeans.fit_predict(X)",
        "    ",
        "    # R\u00e9duction dimensionnelle pour visualisation",
        "    pca = PCA(n_components=2)",
        "    X_reduced = pca.fit_transform(X.toarray())",
        "    ",
        "    processing_time = time.time() - start_time",
        "    print(f\"   \u2705 Clustering termin\u00e9 en {processing_time:.2f}s\")",
        "    ",
        "    return clusters, X_reduced, processing_time",
        "",
        "def create_visualization(X_reduced, clusters):",
        "    \"\"\"Cr\u00e9er visualisation r\u00e9sultats\"\"\"",
        "    print(f\"\ud83d\udcca CR\u00c9ATION VISUALISATION...\")",
        "    ",
        "    plt.figure(figsize=(12, 8))",
        "    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters, cmap='viridis', alpha=0.6)",
        "    plt.colorbar(scatter)",
        "    plt.title('\ud83d\ude80 Semantic Clustering Results (GPU Accelerated)', fontsize=16)",
        "    plt.xlabel('PC1')",
        "    plt.ylabel('PC2')",
        "    plt.grid(True, alpha=0.3)",
        "    plt.savefig('semantic_clustering_results.png', dpi=300, bbox_inches='tight')",
        "    plt.show()",
        "    ",
        "    print(f\"   \u2705 Visualisation sauvegard\u00e9e: semantic_clustering_results.png\")",
        "",
        "# MAIN PROCESSING",
        "if __name__ == \"__main__\":",
        "    print(\"\ud83d\ude80 SEMANTIC PROCESSING COLAB ACCELERATION\")",
        "    print(\"=\" * 50)",
        "    ",
        "    # G\u00e9n\u00e9rer donn\u00e9es test",
        "    documents = generate_sample_data(n_docs=20000)  # Large dataset pour test GPU",
        "    ",
        "    # Processing acc\u00e9l\u00e9r\u00e9",
        "    clusters, X_reduced, processing_time = accelerated_clustering(documents)",
        "    ",
        "    # Visualisation",
        "    create_visualization(X_reduced, clusters)",
        "    ",
        "    # Rapport performance",
        "    print(f\"\\n\ud83d\udcca RAPPORT PERFORMANCE:\")",
        "    print(f\"   \ud83d\udcc4 Documents trait\u00e9s: {len(documents):,}\")",
        "    print(f\"   \u23f1\ufe0f Temps processing: {processing_time:.2f}s\")",
        "    print(f\"   \u26a1 Throughput: {len(documents)/processing_time:.0f} docs/sec\")",
        "    print(f\"   \ud83d\ude80 GPU utilis\u00e9: {torch.cuda.is_available() if 'torch' in locals() else 'Non d\u00e9tect\u00e9'}\")",
        "    ",
        "    print(f\"\\n\u2705 SEMANTIC PROCESSING COMPLETED!\")",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# \ud83d\udcca EXPORT R\u00c9SULTATS\\n",
        "import json\\n",
        "from datetime import datetime\\n",
        "\\n",
        "# Cr\u00e9er rapport final\\n",
        "final_report = {\\n",
        "    'timestamp': datetime.now().isoformat(),\\n",
        "    'notebook': '\" + notebook_name + \"',\\n",
        "    'status': 'completed',\\n",
        "    'gpu_used': torch.cuda.is_available() if 'torch' in locals() else False,\\n",
        "    'results_summary': 'Processing completed successfully'\\n",
        "}\\n",
        "\\n",
        "# Sauvegarder rapport\\n",
        "with open(f'colab_results_{notebook_name}.json', 'w') as f:\\n",
        "    json.dump(final_report, f, indent=2)\\n",
        "    \\n",
        "print('\u2705 Traitement termin\u00e9!')\\n",
        "print('\ud83d\udcc4 Rapport sauvegard\u00e9')\\n",
        "\\n",
        "# Download link pour r\u00e9cup\u00e9ration\\n",
        "from google.colab import files\\n",
        "files.download(f'colab_results_{notebook_name}.json')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}